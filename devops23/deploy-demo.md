## Hands-On Time

---

# Deploying Releases With Zero-Downtime


## Deploying New Releases

---

```bash
cat deploy/go-demo-2-db.yml

kubectl create -f deploy/go-demo-2-db.yml --record

kubectl get -f deploy/go-demo-2-db.yml

kubectl describe -f deploy/go-demo-2-db.yml

kubectl get all
```

Note:
If you compare this Deployment with the ReplicaSet we created in the previous chapter, you’ll probably have a hard time finding a difference. Apart from the kind field, they are the same. Since, in this case, both the Deployment and the ReplicaSet are the same, you might be wondering what the advantage of using one over the other is. We will regularly add --record to the kubectl create commands. This allows us to track each change to our resources such as a Deployments.
`kubectl describe -f deploy/go-demo-2-db.yml`
From the Events section, we can observe that the Deployment created a ReplicaSet. Or, to be more precise, that it scaled it. That is interesting. It shows that Deployments control ReplicaSets. The Deployment created the ReplicaSet which, in turn, created Pods. Let’s confirm that by retrieving the list of all the objects.
`kubectl get all`
You’ll notice that contained within the name of the Pod is a hash which matches the hash in the name of the new ReplicaSet, namely f8d4b86ff. Even though it might look like it is a random value, it is not. If you destroy the Deployment and create it again, you’ll notice that the hash in the Pod name and ReplicaSet name remain consistent. This value is generated by hashing the PodTemplate of the ReplicaSet. As long as the PodTemplate is the same, the hash value will be the same as well. That way a Deployment can know whether anything related to the Pods has changed and, if it does, will create a new ReplicaSet. The kubectl set image command is not the only way to update a Deployment. We could also have used kubectl edit as well. The command would be as follows. Please do NOT execute it. If you do (against my advice), you’ll need to type :q followed by the enter key to exit.


<!-- .slide: data-background="img/deployment.png" data-background-size="contain" -->


<!-- .slide: data-background="img/seq_deploy_ch06.png" data-background-size="contain" -->


## Updating Deployments

---

```bash
kubectl set image -f deploy/go-demo-2-db.yml db=mongo:3.4 --record

kubectl describe -f deploy/go-demo-2-db.yml

kubectl get all

kubectl edit -f deploy/go-demo-2-db.yml

# Exit with `:q` if vi

kubectl create -f deploy/go-demo-2-db-svc.yml --record
```

Note:
* We changed the image of the `db` container definition in the Deployment
* We described the deployment to confirm that the image changed
* We retrieved all the resources and observed that a new ReplicaSet was created which, in turn, created a new Pod
* We tried to edit the resources definition but gave up since it is a bad practice
* We created a Service for the DB


## Zero-Downtime Deployments

---

```bash
cat deploy/go-demo-2-api.yml

kubectl create -f deploy/go-demo-2-api.yml --record

kubectl get -f deploy/go-demo-2-api.yml

kubectl set image -f deploy/go-demo-2-api.yml \
    api=vfarcic/go-demo-2:2.0 --record

kubectl rollout status -w -f deploy/go-demo-2-api.yml

kubectl describe -f deploy/go-demo-2-api.yml

kubectl rollout history -f deploy/go-demo-2-api.yml

kubectl get rs
```

Note:
Regarding `cat go-demo-2-api`
* `minReadySeconds` defines the minimum number of seconds before Kubernetes starts considering the Pods healthy. We put the value of this field to 1 second. The default value is 0, meaning that the Pods will be considered available as soon as they are ready and, when specified, livenessProbe returns OK. If in doubt, omit this field and leave it to the default value of 0. We defined it mostly for demonstration purposes.
* `revisionHistoryLimit`. It defines the number of old ReplicaSets we can rollback. Like most of the fields, it is set to the sensible default value of 10. We changed it to 5 and, as a result, we will be able to rollback to any of the previous five ReplicaSets.
* The `strategy` can be either the `RollingUpdate` or the `Recreate` type. `RollingUpdate` is the default strategy, and the only that will allow for Zero-Downtime deployments
* When `RollingUpdate` is the strategy of choice, it can be fine-tuned with the `maxSurge` and `maxUnavailable` fields. The former defines the maximum number of Pods that can exceed the desired number (set using replicas). It can be set to an absolute number (e.g., 2) or a percentage (e.g., 35%). The total number of Pods will never exceed the desired number (set using replicas) and the maxSurge combined. The default value is 25%.
* `maxUnavailable` defines the maximum number of Pods that are not operational. If, for example, the number of replicas is set to 15 and this field is set to 4, the minimum number of Pods that would run at any given moment would be 11
* We changed the image of the `api` container definition in the API Deployment
* We executed `rollout status` to watch the progress of the update
* We executed `rollout history` and observed that we made two revisions
* We retrieved all the ReplicaSets and observed that new ones we created with each update


<!-- .slide: data-background="img/flow_deploy_ch06.png" data-background-size="contain" -->


## Rolling Back Or Forward?

---

```bash
kubectl rollout undo -f deploy/go-demo-2-api.yml

kubectl describe -f deploy/go-demo-2-api.yml

kubectl rollout history -f deploy/go-demo-2-api.yml

kubectl set image -f deploy/go-demo-2-api.yml \
    api=vfarcic/go-demo-2:3.0 --record

kubectl rollout status -f deploy/go-demo-2-api.yml

kubectl set image -f deploy/go-demo-2-api.yml \
    api=vfarcic/go-demo-2:4.0 --record

kubectl rollout status -f deploy/go-demo-2-api.yml
```

Note:
* We undid the last update
* We described the deployment to observe the events related to ReplicaSets
* We output `rollout history` and observed that a new revision was created
* We updated the image of the `api` twice to generate a few more revisions


## Rolling Back Or Forward?

---

```bash
kubectl rollout history -f deploy/go-demo-2-api.yml

kubectl set image -f deploy/go-demo-2-api.yml \
    api=vfarcic/go-demo-2:2.0 --record

kubectl rollout undo -f deploy/go-demo-2-api.yml --to-revision=4

kubectl rollout history -f deploy/go-demo-2-api.yml
```

Note:
* We output `rollout history` to confirm that all the revisions were recorded
* We are going to execute one more update
* We are going roll out to the revision `4`
* We going to observe through `rollout history` that rollback to a specific revision was indeed performed


## Rolling Back Failures

---

```bash
kubectl set image -f deploy/go-demo-2-api.yml \
    api=vfarcic/go-demo-2:does-not-exist --record

kubectl get rs -l type=api

kubectl rollout status -f deploy/go-demo-2-api.yml

echo $?

kubectl rollout undo -f deploy/go-demo-2-api.yml

kubectl rollout status -f deploy/go-demo-2-api.yml
```

Note:
The output of the `set` command seems to imply that the `does-not-exist` image was successful deployed, when in fact it was not. Executing at `rollout status` confirms the deployment didn't proceed. The new Pods are not running, and the limit was reached. There’s no point to continue trying. If you expected that the Deployment would roll back after it failed, you’re wrong. It will not do such a thing. At least, not without additional addons.  Running `echo $?`confirms the return code of the command is 1. Now that we witnessed the failure we can undo the rollout, and verify that our api is running.




## Rolling Back Failures

---

```bash
kubectl delete -f deploy/go-demo-2-db.yml

kubectl delete -f deploy/go-demo-2-db-svc.yml

kubectl delete -f deploy/go-demo-2-api.yml
```

Note:
Now that we have learned how to rollback no matter whether the problem is a critical bug or inability to run the new release, we can take a short pause from learning new stuff and merge all the definitions we explored thus far into a single YAML file. But, before we do that, we’ll remove the objects we created.


## Merging Everything

---

```bash
cat deploy/go-demo-2.yml

kubectl create -f deploy/go-demo-2.yml --record --save-config

kubectl get -f deploy/go-demo-2.yml
```

Note:
If you start searching for differences with the previous definitions, you will find a few. The `minReadySeconds`, `progressDeadlineSeconds`, `revisionHistoryLimit`, and strategy fields are removed from the go-demo-2-api Deployment. We used them mostly as a way to demonstrate their usage. But, since Kubernetes has sensible defaults, we omitted them from this definition. You’ll also notice that there are two Services even though we created only one in this chapter. We did not need the go-demo-2-api Service in our examples since we didn’t need to access the API. But, for the sake of completeness, it is included in this definition. Finally, the strategy for deploying the database is set to `recreate`. As explained earlier, it is more suited for a single-replica database, even though we did not mount a volume that would preserve the data. Let’s create the objects defined in deploy/ go-demo-2. yml. Remember, with --save-config we’re making sure we can edit the configuration later. The alternative would be to use kubectl apply instead.

## Updating Multiple Objects

---

```bash
cat deploy/different-app-db.yml

kubectl create -f deploy/different-app-db.yml

kubectl get deployments --show-labels

kubectl get deployments -l type=db,vendor=MongoLabs

kubectl set image deployments -l type=db,vendor=MongoLabs \
    db=mongo:3.4 --record

kubectl describe -f deploy/go-demo-2.yml
```

Note:
This this exercise we are creating another `db` applications. The purpose of this is to demonstrate how to update multiple objects using labels. Almost everything in Kubernetes is operated using label selectors. It’s just that sometimes that is obscured from us. We do not have to update an object only by specifying its name or the YAML file where its definition resides. We can also use labels to decide which object should be updated. That opens some interesting possibilities since the selectors might match multiple objects. Imagine that we are running several Deployments with Mongo databases and that the time has come to update them all to a newer release. Before we explore how we could do that, we’ll create another Deployment so that we have at least two with the database Pods. Here we are going to find all the deployments that are a `db` type, with `MongoLabs` vendor. Then we will update all the images that use those labels to a new version of mongo. Finally we will confirm that all mongo images are running `3.4`


## Scaling Deployments

---

```bash
cat deploy/go-demo-2-scaled.yml

kubectl apply -f deploy/go-demo-2-scaled.yml

kubectl get -f deploy/go-demo-2-scaled.yml

kubectl scale deployment go-demo-2-api --replicas 8 --record

kubectl get -f deploy/go-demo-2.yml
```

Note:
* We created a few resources, including Deployment of the API with five replicas
* We retrieved the resources and observed that Deployment is indeed set to have five replicas
* We scaled the Deployment of the API to eight
* We retrieved the resources and observed that Deployment was changed to have eight replicas


## Deployments

---

* Zero-downtime updates<!-- .element: class="fragment" -->


<!-- .slide: data-background="img/deploy-components.png" data-background-size="contain" -->


## What Now?

---

```bash
kubectl delete -f deploy/go-demo-2.yml

kubectl delete -f deploy/different-app-db.yml
```
